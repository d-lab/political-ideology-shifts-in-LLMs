{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0907f0ae-bdd4-4506-b829-75279d730a74",
   "metadata": {},
   "source": [
    "# Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b13d126-d0e6-44e3-9908-c0ebda41b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default sys.path: ['/Users/uqpberna/miniconda3/envs/personas/lib/python312.zip', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/lib-dynload', '', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/site-packages', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/site-packages/setuptools/_vendor']\n",
      "Project root: /Users/uqpberna/Documents/Code/Mapping_and_Influencing_LLMs_Political_Leaning/extension/src\n"
     ]
    }
   ],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reload all modules every time before executing the Python code\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f'default sys.path: {sys.path}')\n",
    "# Probably not needed for pycharm but needed for vscode -----------------------------------\n",
    "PROJ_ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "sys.path.append(PROJ_ROOT)\n",
    "print(f'Project root: {PROJ_ROOT}')\n",
    "# Probably not needed for pycharm but needed for vscode -----------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langdetect import detect, detect_langs, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import json\n",
    "from typing import List, Dict, Union\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5e7f3-0b82-4640-8ea7-b4a6919cff12",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1 - <u>Clean the persona descriptions</u>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ba9ab-b3b4-4ccc-85ef-48bae3e811bd",
   "metadata": {},
   "source": [
    "#### Load data from the Face\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "86bc5318-d031-41be-9d9f-90c57f59b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since proj-persona/PersonaHub couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'persona' at /Users/uqpberna/.cache/huggingface/datasets/proj-persona___persona_hub/persona/0.0.0/ec274c89b6be2d292d69f4705e3ad92c8a26e935 (last modified on Thu Feb 27 16:21:18 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Political Analyst specialized in El Salvador's political landscape.\n",
      "Number of Personas: 200000\n",
      "Statements list contains 62 statements\n",
      "\n",
      "A Political Analyst specialized in El Salvador's political landscape.\n",
      "If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n"
     ]
    }
   ],
   "source": [
    "# Load the PersonaHub dataset\n",
    "personas = load_dataset(\"proj-persona/PersonaHub\", \"persona\")\n",
    "# Fix: Access the data correctly - the dataset structure is different\n",
    "personas_list = personas['train']['persona']  # This gets the list of personas directly\n",
    "print(personas_list[0])\n",
    "print(f\"Number of Personas: {len(personas_list)}\")\n",
    "\n",
    "# Load the political compass statements\n",
    "statements = pd.read_json(\"../../data/raw/political_compass_statements.json\")['statements']\n",
    "print(f\"Statements list contains {len(statements)} statements\")\n",
    "\n",
    "print()\n",
    "print(personas_list[0])\n",
    "print(statements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "85a6da38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac73c93fc0b42cfa7b9017d44f6b1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing persona:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for persona_id, persona in tqdm(enumerate(personas_list), desc=f\"Processing persona\", total=len(personas_list)):\n",
    "    for statement_id, statement in enumerate(statements):\n",
    "        \n",
    "        record = {\n",
    "            'statement_id': statement_id,\n",
    "            'statement': statement,\n",
    "            'persona_id': persona_id,\n",
    "            'persona': persona,\n",
    "        }\n",
    "        \n",
    "        data.append(record)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a5f4e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>statement</th>\n",
       "      <th>persona_id</th>\n",
       "      <th>persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If economic globalisation is inevitable, it sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'd always support my country, whether it was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No one chooses their country of birth, so it's...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Our race has many superior qualities, compared...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The enemy of my enemy is my friend.</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statement_id                                          statement  \\\n",
       "0             0  If economic globalisation is inevitable, it sh...   \n",
       "1             1  I'd always support my country, whether it was ...   \n",
       "2             2  No one chooses their country of birth, so it's...   \n",
       "3             3  Our race has many superior qualities, compared...   \n",
       "4             4                The enemy of my enemy is my friend.   \n",
       "\n",
       "   persona_id                                            persona  \n",
       "0           0  A Political Analyst specialized in El Salvador...  \n",
       "1           0  A Political Analyst specialized in El Salvador...  \n",
       "2           0  A Political Analyst specialized in El Salvador...  \n",
       "3           0  A Political Analyst specialized in El Salvador...  \n",
       "4           0  A Political Analyst specialized in El Salvador...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad7ec1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12400000, 4)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8d71f",
   "metadata": {},
   "source": [
    "#### Language detection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a37c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducible results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_language_single(text: str) -> Dict[str, Union[str, float]]:\n",
    "    \"\"\"\n",
    "    Detect language for a single text with confidence score\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Language code, confidence, and original text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get primary language\n",
    "        lang_code = detect(text)\n",
    "        \n",
    "        # Get confidence scores for all detected languages\n",
    "        lang_probs = detect_langs(text)\n",
    "        confidence = lang_probs[0].prob if lang_probs else 0.0\n",
    "        \n",
    "        return {\n",
    "            'text': text[:100] + '...' if len(text) > 100 else text,\n",
    "            'language': lang_code,\n",
    "            'confidence': round(confidence, 3),\n",
    "            'all_probabilities': [(lang.lang, round(lang.prob, 3)) for lang in lang_probs[:3]]\n",
    "        }\n",
    "    except LangDetectException as e:\n",
    "        return {\n",
    "            'text': text[:100] + '...' if len(text) > 100 else text,\n",
    "            'language': 'unknown',\n",
    "            'confidence': 0.0,\n",
    "            'error': str(e),\n",
    "            'all_probabilities': []\n",
    "        }\n",
    "\n",
    "def detect_languages_batch(personas: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Detect languages for a list of persona descriptions\n",
    "    \n",
    "    Args:\n",
    "        personas (List[str]): List of persona descriptions\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: Results with language detection for each persona\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, persona in tqdm(enumerate(personas), total=len(personas), desc=\"Detecting languages\"):\n",
    "        result = detect_language_single(persona)\n",
    "        result['index'] = i\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_language_distribution(results: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze the distribution of detected languages\n",
    "    \n",
    "    Args:\n",
    "        results (List[Dict]): Results from language detection\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Language distribution statistics\n",
    "    \"\"\"\n",
    "    lang_counts = {}\n",
    "    total_personas = len(results)\n",
    "    \n",
    "    for result in results:\n",
    "        lang = result['language']\n",
    "        lang_counts[lang] = lang_counts.get(lang, 0) + 1\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_langs = sorted(lang_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    distribution = {\n",
    "        'total_personas': total_personas,\n",
    "        'unique_languages': len(lang_counts),\n",
    "        'language_counts': dict(sorted_langs),\n",
    "        'language_percentages': {\n",
    "            lang: round((count / total_personas) * 100, 2) \n",
    "            for lang, count in sorted_langs\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "def save_results(results: List[Dict], filename: str = 'language_detection_results'):\n",
    "    \"\"\"\n",
    "    Save results in multiple formats\n",
    "    \n",
    "    Args:\n",
    "        results (List[Dict]): Detection results\n",
    "        filename (str): Base filename for output files\n",
    "    \"\"\"\n",
    "    # Save as JSON\n",
    "    with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Save as CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(f'{filename}.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Results saved as {filename}.json and {filename}.csv\")\n",
    "\n",
    "# Language code mapping for better readability\n",
    "LANGUAGE_NAMES = {\n",
    "    'en': 'English',\n",
    "    'es': 'Spanish', \n",
    "    'fr': 'French',\n",
    "    'de': 'German',\n",
    "    'it': 'Italian',\n",
    "    'pt': 'Portuguese',\n",
    "    'ru': 'Russian',\n",
    "    'ja': 'Japanese',\n",
    "    'ko': 'Korean',\n",
    "    'zh-cn': 'Chinese (Simplified)',\n",
    "    'zh-tw': 'Chinese (Traditional)',\n",
    "    'ar': 'Arabic',\n",
    "    'hi': 'Hindi',\n",
    "    'th': 'Thai',\n",
    "    'vi': 'Vietnamese',\n",
    "    'nl': 'Dutch',\n",
    "    'sv': 'Swedish',\n",
    "    'no': 'Norwegian',\n",
    "    'da': 'Danish',\n",
    "    'fi': 'Finnish',\n",
    "    'pl': 'Polish',\n",
    "    'tr': 'Turkish',\n",
    "    'cs': 'Czech',\n",
    "    'hu': 'Hungarian',\n",
    "    'ro': 'Romanian',\n",
    "    'bg': 'Bulgarian',\n",
    "    'hr': 'Croatian',\n",
    "    'sk': 'Slovak',\n",
    "    'sl': 'Slovenian',\n",
    "    'et': 'Estonian',\n",
    "    'lv': 'Latvian',\n",
    "    'lt': 'Lithuanian',\n",
    "    'uk': 'Ukrainian',\n",
    "    'be': 'Belarusian',\n",
    "}\n",
    "\n",
    "def get_language_name(lang_code: str) -> str:\n",
    "    \"\"\"Convert language code to readable name\"\"\"\n",
    "    return LANGUAGE_NAMES.get(lang_code, lang_code.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58260b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Language Detection for Persona Descriptions ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fe13ce69b445d5938dc4075e6ef762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Detecting languages:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Language Distribution ===\n",
      "Total personas: 200000\n",
      "Unique languages: 40\n",
      "\n",
      "Language breakdown:\n",
      "  en: 196693 personas (98.35%)\n",
      "  zh-cn: 1086 personas (0.54%)\n",
      "  it: 452 personas (0.23%)\n",
      "  es: 248 personas (0.12%)\n",
      "  pt: 205 personas (0.1%)\n",
      "  ru: 154 personas (0.08%)\n",
      "  ko: 149 personas (0.07%)\n",
      "  ro: 138 personas (0.07%)\n",
      "  fr: 116 personas (0.06%)\n",
      "  af: 104 personas (0.05%)\n",
      "  ca: 93 personas (0.05%)\n",
      "  id: 87 personas (0.04%)\n",
      "  no: 65 personas (0.03%)\n",
      "  de: 59 personas (0.03%)\n",
      "  nl: 54 personas (0.03%)\n",
      "  da: 46 personas (0.02%)\n",
      "  tl: 39 personas (0.02%)\n",
      "  sv: 38 personas (0.02%)\n",
      "  zh-tw: 29 personas (0.01%)\n",
      "  cy: 18 personas (0.01%)\n",
      "  ja: 14 personas (0.01%)\n",
      "  pl: 14 personas (0.01%)\n",
      "  sl: 11 personas (0.01%)\n",
      "  et: 11 personas (0.01%)\n",
      "  hr: 10 personas (0.01%)\n",
      "  tr: 9 personas (0.0%)\n",
      "  hu: 8 personas (0.0%)\n",
      "  so: 7 personas (0.0%)\n",
      "  sk: 7 personas (0.0%)\n",
      "  vi: 6 personas (0.0%)\n",
      "  cs: 6 personas (0.0%)\n",
      "  fi: 6 personas (0.0%)\n",
      "  th: 6 personas (0.0%)\n",
      "  uk: 3 personas (0.0%)\n",
      "  sw: 3 personas (0.0%)\n",
      "  bg: 2 personas (0.0%)\n",
      "  lt: 1 personas (0.0%)\n",
      "  sq: 1 personas (0.0%)\n",
      "  unknown: 1 personas (0.0%)\n",
      "  lv: 1 personas (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Language Detection for Persona Descriptions ===\\n\")\n",
    "\n",
    "results = detect_languages_batch(personas_list)\n",
    "\n",
    "# Analyze distribution\n",
    "distribution = analyze_language_distribution(results)\n",
    "\n",
    "print(f\"\\n=== Language Distribution ===\")\n",
    "print(f\"Total personas: {distribution['total_personas']}\")\n",
    "print(f\"Unique languages: {distribution['unique_languages']}\")\n",
    "print(\"\\nLanguage breakdown:\")\n",
    "for lang, percentage in distribution['language_percentages'].items():\n",
    "    count = distribution['language_counts'][lang]\n",
    "    print(f\"  {lang}: {count} personas ({percentage}%)\")\n",
    "\n",
    "# # Save results\n",
    "# save_results(results, 'persona_language_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df9127cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     persona_id                                            persona language\n",
      "0             0  A Political Analyst specialized in El Salvador...       en\n",
      "62            1  A legal advisor who understands the legal impl...       en\n",
      "124           2  A maternal health advocate focused on raising ...       en\n",
      "186           3  A school basketball team captain who believes ...       en\n",
      "248           4  A determined basketball player who aspires to ...       en\n",
      "310           5  A virtual reality content creator sharing thei...       en\n",
      "372           6  An engineer with a shared sense of humor, who ...       en\n",
      "434           7  an IT project manager who adopted extreme prog...       en\n",
      "496           8  a newly hired general counsel at TurpCo Indust...       en\n",
      "558           9  A divorced father of three seeking legal repre...       en\n"
     ]
    }
   ],
   "source": [
    "persona_language_map = {}\n",
    "for result in results:\n",
    "    persona_id = result['index']\n",
    "    detected_language = result['language']\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    # Store both language code and confidence if needed\n",
    "    persona_language_map[persona_id] = {\n",
    "        'language': detected_language,\n",
    "        # 'language_name': get_language_name(detected_language),\n",
    "        # 'confidence': confidence\n",
    "    }\n",
    "\n",
    "# Add language columns to the DataFrame\n",
    "# df['language_code'] = df['persona_id'].map(lambda x: persona_language_map[x]['language'])\n",
    "df['language'] = df['persona_id'].map(lambda x: persona_language_map[x]['language'])\n",
    "# df['language_name'] = df['persona_id'].map(lambda x: persona_language_map[x]['language_name'])\n",
    "# df['language_confidence'] = df['persona_id'].map(lambda x: persona_language_map[x]['confidence'])\n",
    "\n",
    "# Display sample results\n",
    "print(df[['persona_id', 'persona', 'language']].drop_duplicates('persona_id').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4558a661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Language Distribution in DataFrame ===\n",
      "language\n",
      "en         196693\n",
      "zh-cn        1086\n",
      "it            452\n",
      "es            248\n",
      "pt            205\n",
      "ru            154\n",
      "ko            149\n",
      "ro            138\n",
      "fr            116\n",
      "af            104\n",
      "ca             93\n",
      "id             87\n",
      "no             65\n",
      "de             59\n",
      "nl             54\n",
      "da             46\n",
      "tl             39\n",
      "sv             38\n",
      "zh-tw          29\n",
      "cy             18\n",
      "pl             14\n",
      "ja             14\n",
      "et             11\n",
      "sl             11\n",
      "hr             10\n",
      "tr              9\n",
      "hu              8\n",
      "sk              7\n",
      "so              7\n",
      "fi              6\n",
      "cs              6\n",
      "vi              6\n",
      "th              6\n",
      "uk              3\n",
      "sw              3\n",
      "bg              2\n",
      "lt              1\n",
      "sq              1\n",
      "unknown         1\n",
      "lv              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show language distribution in the DataFrame\n",
    "print(\"\\n=== Language Distribution in DataFrame ===\")\n",
    "language_counts = df.drop_duplicates('persona_id')['language'].value_counts()\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132953c1",
   "metadata": {},
   "source": [
    "#### Check initial characters\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2270f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 starting patterns:\n",
      "'A ': 140992 personas\n",
      "'An': 24579 personas\n",
      "'a ': 21269 personas\n",
      "'an': 3454 personas\n",
      "'I ': 2854 personas\n",
      "'Th': 1384 personas\n",
      "'As': 596 personas\n",
      "'I'': 500 personas\n",
      "'我是': 331 personas\n",
      "'一个': 330 personas\n",
      "'Un': 286 personas\n",
      "'一位': 213 personas\n",
      "'Um': 140 personas\n",
      "'Co': 65 personas\n",
      "'Pr': 61 personas\n",
      "'So': 61 personas\n",
      "'一名': 58 personas\n",
      "'In': 55 personas\n",
      "'Fo': 49 personas\n",
      "'Re': 48 personas\n",
      "'Ma': 47 personas\n",
      "'Lo': 46 personas\n",
      "'En': 46 personas\n",
      "'Ch': 44 personas\n",
      "'Hi': 43 personas\n",
      "'Se': 41 personas\n",
      "'Mi': 38 personas\n",
      "'Ja': 36 personas\n",
      "'Ex': 33 personas\n",
      "'Fi': 31 personas\n",
      "'th': 31 personas\n",
      "'Pa': 30 personas\n",
      "'Da': 29 personas\n",
      "'Al': 28 personas\n",
      "'Yo': 27 personas\n",
      "'Sp': 27 personas\n",
      "'Ca': 27 personas\n",
      "'Br': 26 personas\n",
      "'I’': 25 personas\n",
      "'香港': 24 personas\n",
      "'Po': 24 personas\n",
      "'Jo': 24 personas\n",
      "'Dr': 23 personas\n",
      "'Ar': 22 personas\n",
      "'Li': 21 personas\n",
      "'Am': 21 personas\n",
      "'Be': 21 personas\n",
      "'Ru': 20 personas\n",
      "'No': 20 personas\n",
      "'：一': 20 personas\n",
      "'La': 20 personas\n",
      "'Te': 19 personas\n",
      "'We': 19 personas\n",
      "'Fr': 19 personas\n",
      "'Ne': 18 personas\n",
      "'Mo': 18 personas\n",
      "'Ro': 17 personas\n",
      "'Ge': 17 personas\n",
      "'Ei': 17 personas\n",
      "'Gr': 17 personas\n",
      "'He': 17 personas\n",
      "'Ст': 17 personas\n",
      "'Bu': 16 personas\n",
      "'Bo': 16 personas\n",
      "'Py': 16 personas\n",
      "'El': 15 personas\n",
      "'Me': 15 personas\n",
      "'Au': 15 personas\n",
      "'Cu': 15 personas\n",
      "'Ha': 14 personas\n",
      "'Ta': 14 personas\n",
      "'Ba': 14 personas\n",
      "'Я ': 14 personas\n",
      "'Mu': 14 personas\n",
      "'Si': 14 personas\n",
      "'Fa': 13 personas\n",
      "'Пр': 13 personas\n",
      "'日本': 13 personas\n",
      "'De': 13 personas\n",
      "'Av': 13 personas\n",
      "'Cr': 12 personas\n",
      "'Su': 12 personas\n",
      "'On': 12 personas\n",
      "'Em': 12 personas\n",
      "'Ni': 12 personas\n",
      "'Ра': 11 personas\n",
      "'Ju': 11 personas\n",
      "'Sc': 11 personas\n",
      "'Tr': 11 personas\n",
      "'Ag': 11 personas\n",
      "'IT': 11 personas\n",
      "'My': 10 personas\n",
      "'中国': 10 personas\n",
      "'St': 10 personas\n",
      "'Sw': 10 personas\n",
      "'Hu': 10 personas\n",
      "'Di': 10 personas\n",
      "'Le': 10 personas\n",
      "'as': 10 personas\n",
      "'Pu': 9 personas\n",
      "'Ir': 9 personas\n",
      "'Ow': 9 personas\n",
      "'Bi': 9 personas\n",
      "'Fe': 9 personas\n",
      "'Ho': 9 personas\n",
      "'Je': 9 personas\n",
      "'di': 9 personas\n",
      "'Sa': 9 personas\n",
      "'Af': 8 personas\n",
      "'Es': 8 personas\n",
      "'台灣': 8 personas\n",
      "'Na': 8 personas\n",
      "'Wo': 8 personas\n",
      "'It': 7 personas\n",
      "'Eu': 7 personas\n",
      "'Ap': 7 personas\n",
      "'加拿': 7 personas\n",
      "'Ph': 7 personas\n",
      "'fo': 7 personas\n",
      "'Ce': 7 personas\n",
      "'Vi': 7 personas\n",
      "'av': 7 personas\n",
      "'Tw': 7 personas\n",
      "'Ve': 7 personas\n",
      "'Wh': 7 personas\n",
      "'Ol': 7 personas\n",
      "'Ad': 7 personas\n",
      "'Cl': 7 personas\n",
      "'un': 7 personas\n",
      "'To': 6 personas\n",
      "'Uk': 6 personas\n",
      "'韩国': 6 personas\n",
      "'Ee': 6 personas\n",
      "'Go': 6 personas\n",
      "'Ke': 6 personas\n",
      "'co': 6 personas\n",
      "'Or': 6 personas\n",
      "'นั': 6 personas\n",
      "'Ac': 6 personas\n",
      "'Ec': 6 personas\n",
      "'足球': 5 personas\n",
      "'Du': 5 personas\n",
      "'Ai': 5 personas\n",
      "'so': 5 personas\n",
      "'CE': 5 personas\n",
      "'80': 5 personas\n",
      "'Лю': 5 personas\n",
      "'Et': 5 personas\n",
      "'Tu': 5 personas\n",
      "'en': 5 personas\n",
      "'Bl': 5 personas\n",
      "'Im': 5 personas\n",
      "'de': 5 personas\n",
      "'Ea': 5 personas\n",
      "'Мо': 5 personas\n",
      "'pa': 5 personas\n",
      "'Do': 5 personas\n",
      "'Оп': 5 personas\n",
      "'fa': 5 personas\n",
      "'台湾': 5 personas\n",
      "'Om': 5 personas\n",
      "'Fu': 5 personas\n",
      "'yo': 5 personas\n",
      "'Ру': 5 personas\n",
      "'俄罗': 5 personas\n",
      "'Ве': 4 personas\n",
      "'Ko': 4 personas\n",
      "'环保': 4 personas\n",
      "'Is': 4 personas\n",
      "'Уч': 4 personas\n",
      "'ex': 4 personas\n",
      "'Ka': 4 personas\n",
      "'Ро': 4 personas\n",
      "'Ме': 4 personas\n",
      "'意大': 4 personas\n",
      "'Ya': 4 personas\n",
      "'re': 4 personas\n",
      "'Lu': 4 personas\n",
      "'UK': 4 personas\n",
      "'Ri': 4 personas\n",
      "'Sm': 4 personas\n",
      "'At': 4 personas\n",
      "'hi': 4 personas\n",
      "'Za': 4 personas\n",
      "'中年': 4 personas\n",
      "'Op': 4 personas\n",
      "'Sh': 4 personas\n",
      "'Pe': 3 personas\n",
      "'挪威': 3 personas\n",
      "'Yu': 3 personas\n",
      "'Ed': 3 personas\n",
      "'Сп': 3 personas\n",
      "'Sr': 3 personas\n",
      "'MC': 3 personas\n",
      "'新加': 3 personas\n",
      "'棒球': 3 personas\n",
      "'Sl': 3 personas\n",
      "'韩流': 3 personas\n",
      "'ei': 3 personas\n",
      "'Eg': 3 personas\n",
      "'Ис': 3 personas\n",
      "'tr': 3 personas\n",
      "'lo': 3 personas\n",
      "'老一': 3 personas\n",
      "'篮球': 3 personas\n",
      "'Sy': 3 personas\n",
      "'Ra': 3 personas\n",
      "'Ди': 3 personas\n",
      "'Cz': 3 personas\n",
      "'德国': 3 personas\n",
      "'SQ': 3 personas\n",
      "'Er': 3 personas\n",
      "'Gu': 3 personas\n",
      "'荷兰': 3 personas\n",
      "'：A': 3 personas\n",
      "'Вл': 3 personas\n",
      "'Ug': 3 personas\n",
      "'iO': 3 personas\n",
      "'Ye': 3 personas\n",
      "'瑞士': 3 personas\n",
      "'Ji': 3 personas\n",
      "'ca': 3 personas\n",
      "'：我': 3 personas\n",
      "'Ga': 3 personas\n",
      "'30': 2 personas\n",
      "'65': 2 personas\n",
      "'美国': 2 personas\n",
      "'Pi': 2 personas\n",
      "'退休': 2 personas\n",
      "'Ко': 2 personas\n",
      "'\"S': 2 personas\n",
      "'Ly': 2 personas\n",
      "'一個': 2 personas\n",
      "'作为': 2 personas\n",
      "'长期': 2 personas\n",
      "'Wi': 2 personas\n",
      "'Яв': 2 personas\n",
      "'文学': 2 personas\n",
      "'Ku': 2 personas\n",
      "'Ot': 2 personas\n",
      "'fe': 2 personas\n",
      "'Ма': 2 personas\n",
      "'mi': 2 personas\n",
      "'瑞典': 2 personas\n",
      "'熱衷': 2 personas\n",
      "'M.': 2 personas\n",
      "'电影': 2 personas\n",
      "'Не': 2 personas\n",
      "'音乐': 2 personas\n",
      "'Си': 2 personas\n",
      "'PH': 2 personas\n",
      "'Ev': 2 personas\n",
      "'la': 2 personas\n",
      "'泰剧': 2 personas\n",
      "'in': 2 personas\n",
      "'法国': 2 personas\n",
      "'Zo': 2 personas\n",
      "'滑雪': 2 personas\n",
      "'Kn': 2 personas\n",
      "'fi': 2 personas\n",
      "'60': 2 personas\n",
      "'Os': 2 personas\n",
      "'te': 2 personas\n",
      "'Те': 2 personas\n",
      "'no': 2 personas\n",
      "'泰国': 2 personas\n",
      "'漫画': 2 personas\n",
      "'Ин': 2 personas\n",
      "'we': 2 personas\n",
      "'马来': 2 personas\n",
      "'pr': 2 personas\n",
      "'50': 2 personas\n",
      "'曲棍': 2 personas\n",
      "'Wr': 2 personas\n",
      "'Cy': 2 personas\n",
      "'文化': 2 personas\n",
      "'Sé': 2 personas\n",
      "'я ': 2 personas\n",
      "'Ic': 2 personas\n",
      "'伊朗': 2 personas\n",
      "'ba': 2 personas\n",
      "'Ob': 2 personas\n",
      "'pe': 2 personas\n",
      "'Zi': 2 personas\n",
      "'AW': 2 personas\n",
      "'po': 2 personas\n",
      "'Ur': 2 personas\n",
      "'热心': 2 personas\n",
      "'Zh': 2 personas\n",
      "'中学': 2 personas\n",
      "'Ah': 2 personas\n",
      "'45': 2 personas\n",
      "'Ci': 2 personas\n",
      "'Ab': 2 personas\n",
      "'Gl': 2 personas\n",
      "'BB': 2 personas\n",
      "'Pl': 2 personas\n",
      "'sp': 2 personas\n",
      "'Sk': 1 personas\n",
      "'\"D': 1 personas\n",
      "'WW': 1 personas\n",
      "'O ': 1 personas\n",
      "'地方': 1 personas\n",
      "'羅馬': 1 personas\n",
      "'外籍': 1 personas\n",
      "'Ай': 1 personas\n",
      "''A': 1 personas\n",
      "'MY': 1 personas\n",
      "'Му': 1 personas\n",
      "'击剑': 1 personas\n",
      "'LE': 1 personas\n",
      "'JS': 1 personas\n",
      "'33': 1 personas\n",
      "'资深': 1 personas\n",
      "'Ky': 1 personas\n",
      "'US': 1 personas\n",
      "'塞尔': 1 personas\n",
      "'邵国': 1 personas\n",
      "'熱心': 1 personas\n",
      "'狂热': 1 personas\n",
      "'冬季': 1 personas\n",
      "'Ia': 1 personas\n",
      "'星漫': 1 personas\n",
      "'藏族': 1 personas\n",
      "'Эк': 1 personas\n",
      "'K'': 1 personas\n",
      "'是一': 1 personas\n",
      "''B': 1 personas\n",
      "'网球': 1 personas\n",
      "'喜剧': 1 personas\n",
      "'Ti': 1 personas\n",
      "'UN': 1 personas\n",
      "'RM': 1 personas\n",
      "'Lj': 1 personas\n",
      "'Ry': 1 personas\n",
      "'天文': 1 personas\n",
      "'地下': 1 personas\n",
      "'年轻': 1 personas\n",
      "'徐欢': 1 personas\n",
      "'生活': 1 personas\n",
      "'AS': 1 personas\n",
      "'职业': 1 personas\n",
      "'深受': 1 personas\n",
      "'Об': 1 personas\n",
      "'UE': 1 personas\n",
      "'li': 1 personas\n",
      "'终身': 1 personas\n",
      "'75': 1 personas\n",
      "'Dw': 1 personas\n",
      "'or': 1 personas\n",
      "'A'': 1 personas\n",
      "'台北': 1 personas\n",
      "'国际': 1 personas\n",
      "'芬兰': 1 personas\n",
      "'影评': 1 personas\n",
      "'CG': 1 personas\n",
      "'Ty': 1 personas\n",
      "'ст': 1 personas\n",
      "'日高': 1 personas\n",
      "'Va': 1 personas\n",
      "'地质': 1 personas\n",
      "'对公': 1 personas\n",
      "'独立': 1 personas\n",
      "'曾經': 1 personas\n",
      "'家长': 1 personas\n",
      "'渡边': 1 personas\n",
      "'江西': 1 personas\n",
      "'火锅': 1 personas\n",
      "'身处': 1 personas\n",
      "'北卡': 1 personas\n",
      "'am': 1 personas\n",
      "'澳大': 1 personas\n",
      "'Aa': 1 personas\n",
      "'住房': 1 personas\n",
      "'\"二': 1 personas\n",
      "'ру': 1 personas\n",
      "'对香': 1 personas\n",
      "'ch': 1 personas\n",
      "'A&': 1 personas\n",
      "'Мл': 1 personas\n",
      "'说唱': 1 personas\n",
      "'我曾': 1 personas\n",
      "'纽约': 1 personas\n",
      "'高中': 1 personas\n",
      "'Зд': 1 personas\n",
      "'7t': 1 personas\n",
      "'高科': 1 personas\n",
      "'我喜': 1 personas\n",
      "'[C': 1 personas\n",
      "'自行': 1 personas\n",
      "'无比': 1 personas\n",
      "'Кр': 1 personas\n",
      "'Fl': 1 personas\n",
      "'fu': 1 personas\n",
      "'跟随': 1 personas\n",
      "'47': 1 personas\n",
      "'，a': 1 personas\n",
      "'A,': 1 personas\n",
      "'歐洲': 1 personas\n",
      "'受伤': 1 personas\n",
      "'UB': 1 personas\n",
      "'在非': 1 personas\n",
      "'电视': 1 personas\n",
      "'DC': 1 personas\n",
      "'驻香': 1 personas\n",
      "'ha': 1 personas\n",
      "'學術': 1 personas\n",
      "'港生': 1 personas\n",
      "'MI': 1 personas\n",
      "'15': 1 personas\n",
      "'Ki': 1 personas\n",
      "'波兰': 1 personas\n",
      "'pu': 1 personas\n",
      "'金华': 1 personas\n",
      "'热衷': 1 personas\n",
      "'大学': 1 personas\n",
      "'F#': 1 personas\n",
      "'яв': 1 personas\n",
      "'AV': 1 personas\n",
      "'um': 1 personas\n",
      "'奥林': 1 personas\n",
      "'在校': 1 personas\n",
      "'ar': 1 personas\n",
      "'Hä': 1 personas\n",
      "'Gi': 1 personas\n",
      "'前賽': 1 personas\n",
      "'Aw': 1 personas\n",
      "'彼得': 1 personas\n",
      "'평화': 1 personas\n",
      "'AK': 1 personas\n",
      "'До': 1 personas\n",
      "'，一': 1 personas\n",
      "'迷恋': 1 personas\n",
      "'韩剧': 1 personas\n",
      "'心地': 1 personas\n",
      "'非常': 1 personas\n",
      "'对现': 1 personas\n",
      "'围棋': 1 personas\n",
      "'您是': 1 personas\n",
      "'热爱': 1 personas\n",
      "'Ay': 1 personas\n",
      "'Бъ': 1 personas\n",
      "'高校': 1 personas\n",
      "'ແປ': 1 personas\n",
      "'乒乓': 1 personas\n",
      "'非中': 1 personas\n",
      "'_R': 1 personas\n",
      "'sc': 1 personas\n",
      "'华中': 1 personas\n",
      "'Кв': 1 personas\n",
      "'Il': 1 personas\n",
      "'打工': 1 personas\n",
      "'麦克': 1 personas\n",
      "'东野': 1 personas\n",
      "'Iv': 1 personas\n",
      "'ファ': 1 personas\n",
      "'\"C': 1 personas\n",
      "'RJ': 1 personas\n",
      "'By': 1 personas\n",
      "'：资': 1 personas\n",
      "'战争': 1 personas\n",
      "'对日': 1 personas\n",
      "'常常': 1 personas\n",
      "'旅居': 1 personas\n",
      "'cl': 1 personas\n",
      "'：b': 1 personas\n",
      "'40': 1 personas\n",
      "'Of': 1 personas\n",
      "'Со': 1 personas\n",
      "'is': 1 personas\n",
      "'Тр': 1 personas\n",
      "'кр': 1 personas\n",
      "'up': 1 personas\n",
      "'近年': 1 personas\n",
      "'оп': 1 personas\n",
      "'追悼': 1 personas\n",
      "'TV': 1 personas\n",
      "'bo': 1 personas\n",
      "'英格': 1 personas\n",
      "'西非': 1 personas\n",
      "'冰壶': 1 personas\n",
      "'喜欢': 1 personas\n",
      "'AI': 1 personas\n",
      "'情有': 1 personas\n",
      "'吉娜': 1 personas\n",
      "'Фо': 1 personas\n",
      "'澳門': 1 personas\n",
      "'《O': 1 personas\n",
      "'硬核': 1 personas\n",
      "'PR': 1 personas\n",
      "''8': 1 personas\n",
      "'A[': 1 personas\n",
      "'al': 1 personas\n",
      "'J.': 1 personas\n",
      "'轮椅': 1 personas\n",
      "'：日': 1 personas\n",
      "'mo': 1 personas\n",
      "'價值': 1 personas\n",
      "'：硬': 1 personas\n",
      "'捷克': 1 personas\n",
      "'Ли': 1 personas\n",
      "'琼斯': 1 personas\n",
      "'Жу': 1 personas\n",
      "'A9': 1 personas\n",
      "'：足': 1 personas\n",
      "'热忱': 1 personas\n",
      "'成熟': 1 personas\n",
      "'韓国': 1 personas\n",
      "'А ': 1 personas\n",
      "'酷爱': 1 personas\n",
      "'对近': 1 personas\n",
      "'SN': 1 personas\n",
      "'印度': 1 personas\n",
      "'Qa': 1 personas\n",
      "'em': 1 personas\n",
      "'Aq': 1 personas\n",
      "'轻小': 1 personas\n",
      "'Øy': 1 personas\n",
      "'bi': 1 personas\n",
      "'为全': 1 personas\n",
      "'Ib': 1 personas\n",
      "'西川': 1 personas\n",
      "'Ос': 1 personas\n",
      "'Пе': 1 personas\n",
      "'体育': 1 personas\n",
      "'Y ': 1 personas\n",
      "'Sv': 1 personas\n",
      "'移居': 1 personas\n",
      "'Up': 1 personas\n",
      "'番茄': 1 personas\n",
      "'\"J': 1 personas\n",
      "'Ба': 1 personas\n",
      "'eg': 1 personas\n",
      "'Hy': 1 personas\n",
      "'RO': 1 personas\n",
      "'25': 1 personas\n",
      "'苏格': 1 personas\n",
      "'拉脱': 1 personas\n",
      "'На': 1 personas\n",
      "'身为': 1 personas\n",
      "'电子': 1 personas\n",
      "'吃瓜': 1 personas\n",
      "'ve': 1 personas\n",
      "'7-': 1 personas\n",
      "'20': 1 personas\n",
      "'ma': 1 personas\n",
      "'墨西': 1 personas\n",
      "'sm': 1 personas\n",
      "'ed': 1 personas\n",
      "'安哥': 1 personas\n",
      "'哲学': 1 personas\n",
      "'Wa': 1 personas\n",
      "'平凡': 1 personas\n",
      "'馬克': 1 personas\n",
      "'ov': 1 personas\n",
      "'Та': 1 personas\n",
      "'su': 1 personas\n",
      "'格里': 1 personas\n",
      "'Бэ': 1 personas\n",
      "'JJ': 1 personas\n",
      "'汽车': 1 personas\n",
      "'刚刚': 1 personas\n",
      "'南韓': 1 personas\n",
      "'立陶': 1 personas\n",
      "'NC': 1 personas\n",
      "'以面': 1 personas\n",
      "'菲律': 1 personas\n",
      "'ge': 1 personas\n",
      "'K-': 1 personas\n",
      "'锦龙': 1 personas\n",
      "'CP': 1 personas\n",
      "'Ам': 1 personas\n",
      "'Би': 1 personas\n",
      "'\"a': 1 personas\n",
      "'大阪': 1 personas\n",
      "'Бр': 1 personas\n",
      "'Пс': 1 personas\n",
      "'19': 1 personas\n",
      "'Io': 1 personas\n",
      "'Ан': 1 personas\n",
      "'毫无': 1 personas\n",
      "'Yh': 1 personas\n",
      "'Че': 1 personas\n",
      "'懷舊': 1 personas\n",
      "'运动': 1 personas\n",
      "'在深': 1 personas\n",
      "'孟加': 1 personas\n",
      "'Ар': 1 personas\n",
      "'日劇': 1 personas\n",
      "'mu': 1 personas\n",
      "'凯特': 1 personas\n",
      "'IO': 1 personas\n",
      "'31': 1 personas\n",
      "'濃厚': 1 personas\n",
      "'69': 1 personas\n",
      "'Od': 1 personas\n",
      "'Vo': 1 personas\n",
      "'70': 1 personas\n",
      "'熱愛': 1 personas\n",
      "'康涅': 1 personas\n",
      "'Gh': 1 personas\n",
      "'任天': 1 personas\n",
      "'赛车': 1 personas\n",
      "''s': 1 personas\n",
      "'青春': 1 personas\n",
      "'对羽': 1 personas\n",
      "'科学': 1 personas\n",
      "'政治': 1 personas\n",
      "'ME': 1 personas\n",
      "'情感': 1 personas\n",
      "'羽球': 1 personas\n",
      "'是基': 1 personas\n",
      "'● ': 1 personas\n",
      "'to': 1 personas\n",
      "'PT': 1 personas\n",
      "'PC': 1 personas\n",
      "'35': 1 personas\n",
      "'ru': 1 personas\n",
      "'Вы': 1 personas\n",
      "'日剧': 1 personas\n",
      "'专注': 1 personas\n",
      "'：S': 1 personas\n",
      "'长洲': 1 personas\n",
      "'Id': 1 personas\n",
      "'寡默': 1 personas\n",
      "'刘思': 1 personas\n",
      "'律师': 1 personas\n",
      "'do': 1 personas\n",
      "'MS': 1 personas\n"
     ]
    }
   ],
   "source": [
    "# Count and print the first 2 characters of each description\n",
    "def count_first_two_characters(personas):\n",
    "    # Initialize the counter dictionary\n",
    "    first_two_counts = defaultdict(int)\n",
    "    \n",
    "    for persona in personas:\n",
    "        if len(persona) >= 2:\n",
    "            first_two = persona[:2]\n",
    "            first_two_counts[first_two] += 1\n",
    "    return first_two_counts\n",
    "\n",
    "# Get unique personas that are in 'en' language\n",
    "personas_list = df['persona'].drop_duplicates().tolist()\n",
    "\n",
    "# Call the function with the personas list\n",
    "first_two_counts = count_first_two_characters(personas_list)\n",
    "\n",
    "# Sort the counts in descending order\n",
    "sorted_first_two_counts = sorted(first_two_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted counts\n",
    "print(\"\\nStarting patterns:\")\n",
    "for first_two, count in sorted_first_two_counts:  # Display top 10\n",
    "    print(f\"'{first_two}': {count} personas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9fe11e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of personas not starting with 'An' or 'A ': 10240\n"
     ]
    }
   ],
   "source": [
    "# Count the number of personas not starting with 'An' or 'A ' (case-insensitive)\n",
    "not_starting_with_an_a = sum(1 for persona in personas_list if not (persona.lower().startswith('an ') or persona.lower().startswith('a ')))\n",
    "print(f\"\\nNumber of personas not starting with 'An' or 'A ': {not_starting_with_an_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4080e3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples for each pattern:\n",
      "Example for 'A ': A Political Analyst specialized in El Salvador's political landscape.\n",
      "Example for 'An': An engineer with a shared sense of humor, who has known the comedian since grade school\n",
      "Example for 'a ': a newly hired general counsel at TurpCo Industries\n",
      "Example for 'an': an IT project manager who adopted extreme programming (XP) methodologies on his own team.\n",
      "Example for 'I ': I am a hockey enthusiast who has been following the careers of notable defensemen.\n",
      "Example for 'Th': The town's mail carrier who depends on well-maintained snowmobiles to deliver letters and packages during heavy snow\n",
      "Example for 'As': As a professional fitness trainer who upholds two fascinating doctrines: \"Community Involvement\" and \"Commitment to Charity\", I deeply appreciate activities that foster fitness while providing opportunities to give back to the society.\n",
      "Example for 'I'': I'm a casual snooker fan and amateur player who once dreamed of going pro.\n",
      "Example for 'Co': Country music enthusiast from Texas who's been following Faith Hill's career since he was a teenager\n",
      "Example for 'Pr': Proud mother of Elisabeth Baker, who is supportive and overly-excited.\n"
     ]
    }
   ],
   "source": [
    "# Print one example of each first two characters\n",
    "print(\"\\nExamples for each pattern:\")\n",
    "for first_two, _ in sorted_first_two_counts[:10]:\n",
    "    example_persona = next((p for p in personas_list if p.startswith(first_two)), None)\n",
    "    print(f\"Example for '{first_two}': {example_persona}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c765ac4",
   "metadata": {},
   "source": [
    "#### Format 'A' and 'An'\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5242def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_persona(text):\n",
    "    if pd.isna(text):\n",
    "        return ' '\n",
    "    \n",
    "    # Check if starts with 'An' (uppercase)\n",
    "    if text.startswith('An '):\n",
    "        return 'an ' + text[2:]\n",
    "    # Check if starts with 'A' (uppercase)\n",
    "    elif text.startswith('A '):\n",
    "        return 'a ' + text[2:]\n",
    "    # Check if already starts with 'an' or 'a' (lowercase)\n",
    "    elif text.startswith('an ') or text.startswith('a '):\n",
    "        return text\n",
    "    # Otherwise return a space\n",
    "    else:\n",
    "        return ' '\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df['cleaned_persona'] = df['persona'].apply(clean_persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d37a3f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>statement</th>\n",
       "      <th>persona_id</th>\n",
       "      <th>persona</th>\n",
       "      <th>language</th>\n",
       "      <th>cleaned_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If economic globalisation is inevitable, it sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a  Political Analyst specialized in El Salvado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'd always support my country, whether it was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a  Political Analyst specialized in El Salvado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No one chooses their country of birth, so it's...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a  Political Analyst specialized in El Salvado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Our race has many superior qualities, compared...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a  Political Analyst specialized in El Salvado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The enemy of my enemy is my friend.</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a  Political Analyst specialized in El Salvado...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statement_id                                          statement  \\\n",
       "0             0  If economic globalisation is inevitable, it sh...   \n",
       "1             1  I'd always support my country, whether it was ...   \n",
       "2             2  No one chooses their country of birth, so it's...   \n",
       "3             3  Our race has many superior qualities, compared...   \n",
       "4             4                The enemy of my enemy is my friend.   \n",
       "\n",
       "   persona_id                                            persona language  \\\n",
       "0           0  A Political Analyst specialized in El Salvador...       en   \n",
       "1           0  A Political Analyst specialized in El Salvador...       en   \n",
       "2           0  A Political Analyst specialized in El Salvador...       en   \n",
       "3           0  A Political Analyst specialized in El Salvador...       en   \n",
       "4           0  A Political Analyst specialized in El Salvador...       en   \n",
       "\n",
       "                                     cleaned_persona  \n",
       "0  a  Political Analyst specialized in El Salvado...  \n",
       "1  a  Political Analyst specialized in El Salvado...  \n",
       "2  a  Political Analyst specialized in El Salvado...  \n",
       "3  a  Political Analyst specialized in El Salvado...  \n",
       "4  a  Political Analyst specialized in El Salvado...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912f6502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of personas that were cleaned to ' ': 10240\n"
     ]
    }
   ],
   "source": [
    "# Count the number of ' ' in the cleaned_persona column\n",
    "empty_count = df['cleaned_persona'].value_counts().get(' ', 0)\n",
    "print(f\"\\nNumber of personas that were cleaned to ' ': {empty_count//62}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b8e623c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['statement_id', 'statement', 'persona_id', 'persona', 'language',\n",
       "       'cleaned_persona'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad9ae79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 starting patterns in cleaned personas:\n",
      "'a ': 162261 personas\n",
      "'an': 27499 personas\n"
     ]
    }
   ],
   "source": [
    "# Count and print the possible 2 initial characters in the cleaned personas\n",
    "def count_first_two_characters_cleaned(personas):\n",
    "    first_two_counts = defaultdict(int)\n",
    "    \n",
    "    for persona in personas:\n",
    "        if len(persona) >= 2:\n",
    "            first_two = persona[:2]\n",
    "            first_two_counts[first_two] += 1\n",
    "    return first_two_counts\n",
    "# Get unique cleaned personas\n",
    "cleaned_personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "# Call the function with the cleaned personas list\n",
    "cleaned_first_two_counts = count_first_two_characters_cleaned(cleaned_personas_list)\n",
    "# Sort the counts in descending order\n",
    "sorted_cleaned_first_two_counts = sorted(cleaned_first_two_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# Print the sorted counts\n",
    "print(\"\\nTop 10 starting patterns in cleaned personas:\")\n",
    "for first_two, count in sorted_cleaned_first_two_counts:  # Display top 10\n",
    "    print(f\"'{first_two}': {count} personas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4894f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../../data/interim/half_cleaned_persona.pqt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6f761",
   "metadata": {},
   "source": [
    "#### Translate persona descriptions and third person formatting using GPT (4.1-mini)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "82f8205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data/interim/half_cleaned_persona.pqt')\n",
    "gpt_df = pd.read_parquet('../../data/interim/half_cleaned_persona_gpt-4-1-mini.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "99e01072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['statement_id', 'statement', 'persona_id', 'persona', 'language',\n",
      "       'cleaned_persona'],\n",
      "      dtype='object')\n",
      "(12400000, 6)\n",
      "Index(['statement_id', 'statement', 'persona_id', 'persona', 'language',\n",
      "       'cleaned_persona'],\n",
      "      dtype='object')\n",
      "(200000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(gpt_df.columns)\n",
    "print(gpt_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "834ba2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First persona with language 'zh-cn':\n",
      "我是一位热心的动画影评人，对动画产业有着深刻的了解，同时也是露营爱好者。\n",
      " \n",
      "\n",
      "First persona with language 'zh-cn' in gpt_df:\n",
      "一个对体育不太感兴趣，但热爱宠物狗的人\n",
      "A pet lover who is not very interested in sports.\n"
     ]
    }
   ],
   "source": [
    "OCCURRENCE = 0\n",
    "\n",
    "# From df print the first 'persona' with 'language' == 'zh-cn'\n",
    "print(\"First persona with language 'zh-cn':\")\n",
    "print(df[df['language'] == 'zh-cn']['persona'].iloc[OCCURRENCE])\n",
    "print(df[df['language'] == 'zh-cn']['cleaned_persona'].iloc[OCCURRENCE])\n",
    "# From gpt_df print the first 'persona' with 'language' == 'zh-cn'\n",
    "print(\"\\nFirst persona with language 'zh-cn' in gpt_df:\")\n",
    "print(gpt_df[gpt_df['language'] == 'zh-cn']['persona'].iloc[OCCURRENCE])\n",
    "print(gpt_df[gpt_df['language'] == 'zh-cn']['cleaned_persona'].iloc[OCCURRENCE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "06a97929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473cd62afaea4e8aab035b13fe3c8f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning personas:   0%|          | 0/12400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cycle on df and if 'cleaned_persona' is equal to ' ' then replace it with the corresponding 'cleaned_persona' from gpt_df\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Cleaning personas\"):\n",
    "    if row['cleaned_persona'] == ' ':\n",
    "        gpt_row = gpt_df[gpt_df['persona_id'] == row['persona_id']]\n",
    "        if not gpt_row.empty:\n",
    "            df.at[i, 'cleaned_persona'] = gpt_row['cleaned_persona'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a7b38aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of personas that were cleaned to ' ': 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of ' ' in the cleaned_persona column (the persona that required GPT-4 cleaning)\n",
    "empty_count = df['cleaned_persona'].value_counts().get(' ', 0)\n",
    "print(f\"\\nNumber of personas that were cleaned to ' ': {empty_count//62}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f0e3bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting patterns:\n",
      "'a ': 162261 personas\n",
      "'an': 27499 personas\n",
      "'A ': 7061 personas\n",
      "'An': 2039 personas\n",
      "'5.': 440 personas\n",
      "'Th': 399 personas\n",
      "'Dr': 17 personas\n",
      "'Da': 13 personas\n",
      "'Ch': 12 personas\n",
      "'Jo': 12 personas\n",
      "'Ma': 11 personas\n",
      "'Al': 10 personas\n",
      "'Ja': 7 personas\n",
      "'Ca': 7 personas\n",
      "'El': 6 personas\n",
      "'Tw': 6 personas\n",
      "'Re': 5 personas\n",
      "'Mi': 5 personas\n",
      "'La': 5 personas\n",
      "'Pa': 5 personas\n",
      "'Pr': 5 personas\n",
      "'Br': 4 personas\n",
      "'Su': 4 personas\n",
      "'Av': 4 personas\n",
      "'Ya': 4 personas\n",
      "'He': 4 personas\n",
      "'So': 4 personas\n",
      "'Ow': 4 personas\n",
      "'Ni': 4 personas\n",
      "'Na': 3 personas\n",
      "'Le': 3 personas\n",
      "'Ke': 3 personas\n",
      "'Pe': 3 personas\n",
      "'Li': 3 personas\n",
      "'Se': 3 personas\n",
      "'Ad': 3 personas\n",
      "'Am': 3 personas\n",
      "'Em': 3 personas\n",
      "'Er': 3 personas\n",
      "'Je': 3 personas\n",
      "'Ha': 2 personas\n",
      "'Ba': 2 personas\n",
      "'Ot': 2 personas\n",
      "'We': 2 personas\n",
      "'De': 2 personas\n",
      "'Ro': 2 personas\n",
      "'Ju': 2 personas\n",
      "'Bl': 2 personas\n",
      "'Fo': 2 personas\n",
      "'Lu': 2 personas\n",
      "'Ev': 2 personas\n",
      "'Ne': 2 personas\n",
      "'Ri': 2 personas\n",
      "'Ed': 2 personas\n",
      "'Za': 2 personas\n",
      "'Sa': 2 personas\n",
      "'Tr': 2 personas\n",
      "'As': 2 personas\n",
      "'Ka': 2 personas\n",
      "'Au': 2 personas\n",
      "'Mo': 2 personas\n",
      "'Bo': 2 personas\n",
      "'Do': 2 personas\n",
      "'To': 2 personas\n",
      "'Ol': 2 personas\n",
      "'Zh': 2 personas\n",
      "'Ah': 2 personas\n",
      "'Gr': 2 personas\n",
      "'St': 2 personas\n",
      "'Fa': 1 personas\n",
      "'Ly': 1 personas\n",
      "'Ia': 1 personas\n",
      "'Ry': 1 personas\n",
      "'Ap': 1 personas\n",
      "'M.': 1 personas\n",
      "'Po': 1 personas\n",
      "'Ag': 1 personas\n",
      "'Vi': 1 personas\n",
      "'In': 1 personas\n",
      "'Ra': 1 personas\n",
      "'Es': 1 personas\n",
      "'Ho': 1 personas\n",
      "'Aa': 1 personas\n",
      "'Cr': 1 personas\n",
      "'Di': 1 personas\n",
      "'Os': 1 personas\n",
      "'Fr': 1 personas\n",
      "'Ar': 1 personas\n",
      "'Om': 1 personas\n",
      "'Ge': 1 personas\n",
      "'Gi': 1 personas\n",
      "'Bi': 1 personas\n",
      "'Ay': 1 personas\n",
      "'Ec': 1 personas\n",
      "'Lo': 1 personas\n",
      "'Ea': 1 personas\n",
      "'Cl': 1 personas\n",
      "'Hi': 1 personas\n",
      "'Iv': 1 personas\n",
      "'Be': 1 personas\n",
      "'Ph': 1 personas\n",
      "'Uk': 1 personas\n",
      "'Øy': 1 personas\n",
      "'Má': 1 personas\n",
      "'Ib': 1 personas\n",
      "'Sv': 1 personas\n",
      "'Sp': 1 personas\n",
      "'Co': 1 personas\n",
      "'Ji': 1 personas\n",
      "'Ta': 1 personas\n",
      "'Yu': 1 personas\n",
      "'CP': 1 personas\n",
      "'Si': 1 personas\n",
      "'Yh': 1 personas\n",
      "'Ga': 1 personas\n",
      "'Go': 1 personas\n",
      "'Fe': 1 personas\n",
      "'Pi': 1 personas\n",
      "'Et': 1 personas\n",
      "'Id': 1 personas\n",
      "'Sé': 1 personas\n"
     ]
    }
   ],
   "source": [
    "# Count and print the first 2 characters of each description\n",
    "def count_first_two_characters(personas):\n",
    "    # Initialize the counter dictionary\n",
    "    first_two_counts = defaultdict(int)\n",
    "    \n",
    "    for persona in personas:\n",
    "        if len(persona) >= 2:\n",
    "            first_two = persona[:2]\n",
    "            first_two_counts[first_two] += 1\n",
    "    return first_two_counts\n",
    "\n",
    "# Get unique personas that are in 'en' language\n",
    "personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "\n",
    "# Call the function with the personas list\n",
    "first_two_counts = count_first_two_characters(personas_list)\n",
    "\n",
    "# Sort the counts in descending order\n",
    "sorted_first_two_counts = sorted(first_two_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted counts\n",
    "print(\"\\nStarting patterns:\")\n",
    "for first_two, count in sorted_first_two_counts:  # Display top 10\n",
    "    print(f\"'{first_two}': {count} personas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "58ed5d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. A renowned professor known for challenging their own methodologies and predictions.\n"
     ]
    }
   ],
   "source": [
    "# Print examples of cleaned persona starting with '5.'\n",
    "for persona in df['cleaned_persona']:\n",
    "    if persona.startswith('5.'):\n",
    "        print(persona)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe20ec",
   "metadata": {},
   "source": [
    "Because of few-shot we have '5.' sometimes  ===>  remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e0178217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_persona_description(persona):\n",
    "    if pd.isna(persona):\n",
    "        return persona\n",
    "    \n",
    "    # Convert to string to ensure we can work with it\n",
    "    persona_str = str(persona)\n",
    "    \n",
    "    # Check if it starts with '5.' or '5. '\n",
    "    if persona_str.startswith('5.'):\n",
    "        # Remove '5.' and any following spaces\n",
    "        cleaned = persona_str[2:].lstrip()\n",
    "        return cleaned\n",
    "    \n",
    "    # Return unchanged if it doesn't start with '5.'\n",
    "    return persona_str\n",
    "\n",
    "# Apply the cleaning function to your dataframe\n",
    "df['cleaned_persona'] = df['cleaned_persona'].apply(clean_persona_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "fadd94cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting patterns:\n",
      "'a ': 162261 personas\n",
      "'an': 27499 personas\n",
      "'A ': 7201 personas\n",
      "'An': 2102 personas\n",
      "'Th': 596 personas\n",
      "'Dr': 19 personas\n",
      "'Da': 16 personas\n",
      "'Ma': 13 personas\n",
      "'Jo': 13 personas\n",
      "'Ch': 12 personas\n",
      "'Al': 11 personas\n",
      "'Ja': 9 personas\n",
      "'Ca': 7 personas\n",
      "'El': 6 personas\n",
      "'Mi': 6 personas\n",
      "'Pr': 6 personas\n",
      "'He': 6 personas\n",
      "'Tw': 6 personas\n",
      "'Re': 5 personas\n",
      "'La': 5 personas\n",
      "'Pa': 5 personas\n",
      "'Ow': 5 personas\n",
      "'Je': 5 personas\n",
      "'Ni': 5 personas\n",
      "'Br': 4 personas\n",
      "'Su': 4 personas\n",
      "'Av': 4 personas\n",
      "'Ya': 4 personas\n",
      "'Le': 4 personas\n",
      "'So': 4 personas\n",
      "'St': 3 personas\n",
      "'Ro': 3 personas\n",
      "'Ju': 3 personas\n",
      "'Na': 3 personas\n",
      "'Ke': 3 personas\n",
      "'Ne': 3 personas\n",
      "'Pe': 3 personas\n",
      "'Ri': 3 personas\n",
      "'Li': 3 personas\n",
      "'Se': 3 personas\n",
      "'Ad': 3 personas\n",
      "'Am': 3 personas\n",
      "'Sa': 3 personas\n",
      "'Em': 3 personas\n",
      "'Er': 3 personas\n",
      "'Gr': 3 personas\n",
      "'Ha': 2 personas\n",
      "'Si': 2 personas\n",
      "'Hi': 2 personas\n",
      "'Bi': 2 personas\n",
      "'Ba': 2 personas\n",
      "'Ot': 2 personas\n",
      "'We': 2 personas\n",
      "'De': 2 personas\n",
      "'Bl': 2 personas\n",
      "'Fo': 2 personas\n",
      "'Lu': 2 personas\n",
      "'Ev': 2 personas\n",
      "'Ho': 2 personas\n",
      "'Ed': 2 personas\n",
      "'Za': 2 personas\n",
      "'Tr': 2 personas\n",
      "'As': 2 personas\n",
      "'Ji': 2 personas\n",
      "'Lo': 2 personas\n",
      "'Ka': 2 personas\n",
      "'Au': 2 personas\n",
      "'Mo': 2 personas\n",
      "'Bo': 2 personas\n",
      "'Do': 2 personas\n",
      "'To': 2 personas\n",
      "'Ol': 2 personas\n",
      "'Zh': 2 personas\n",
      "'Ah': 2 personas\n",
      "'Fa': 1 personas\n",
      "'Ly': 1 personas\n",
      "'Ia': 1 personas\n",
      "'Tu': 1 personas\n",
      "'Ce': 1 personas\n",
      "'Ry': 1 personas\n",
      "'Ap': 1 personas\n",
      "'M.': 1 personas\n",
      "'Po': 1 personas\n",
      "'Ag': 1 personas\n",
      "'Vi': 1 personas\n",
      "'In': 1 personas\n",
      "'Te': 1 personas\n",
      "'Ra': 1 personas\n",
      "'Es': 1 personas\n",
      "'Aa': 1 personas\n",
      "'Cr': 1 personas\n",
      "'Di': 1 personas\n",
      "'Os': 1 personas\n",
      "'Fr': 1 personas\n",
      "'Ar': 1 personas\n",
      "'Om': 1 personas\n",
      "'On': 1 personas\n",
      "'Ge': 1 personas\n",
      "'Gi': 1 personas\n",
      "'Ay': 1 personas\n",
      "'Ec': 1 personas\n",
      "'Ea': 1 personas\n",
      "'RJ': 1 personas\n",
      "'Cl': 1 personas\n",
      "'Fi': 1 personas\n",
      "'Iv': 1 personas\n",
      "'Be': 1 personas\n",
      "'Ph': 1 personas\n",
      "'Uk': 1 personas\n",
      "'Øy': 1 personas\n",
      "'Má': 1 personas\n",
      "'Ib': 1 personas\n",
      "'Sv': 1 personas\n",
      "'Sp': 1 personas\n",
      "'Co': 1 personas\n",
      "'Ta': 1 personas\n",
      "'Yu': 1 personas\n",
      "'CP': 1 personas\n",
      "'Yh': 1 personas\n",
      "'Ga': 1 personas\n",
      "'Go': 1 personas\n",
      "'Fe': 1 personas\n",
      "'CE': 1 personas\n",
      "'Pi': 1 personas\n",
      "'Et': 1 personas\n",
      "'Id': 1 personas\n",
      "'Sé': 1 personas\n"
     ]
    }
   ],
   "source": [
    "# Get unique personas that are in 'en' language\n",
    "personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "\n",
    "# Call the function with the personas list\n",
    "first_two_counts = count_first_two_characters(personas_list)\n",
    "\n",
    "# Sort the counts in descending order\n",
    "sorted_first_two_counts = sorted(first_two_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted counts\n",
    "print(\"\\nStarting patterns:\")\n",
    "for first_two, count in sorted_first_two_counts:  # Display top 10\n",
    "    print(f\"'{first_two}': {count} personas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1193245",
   "metadata": {},
   "source": [
    "#### Re-format 'A' and 'An'\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "68319560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_persona(text):\n",
    "    if pd.isna(text):\n",
    "        return\n",
    "    \n",
    "    # Check if starts with 'An' (uppercase)\n",
    "    if text.startswith('An '):\n",
    "        return 'an ' + text[3:]\n",
    "    # Check if starts with 'A' (uppercase)\n",
    "    elif text.startswith('A '):\n",
    "        return 'a ' + text[2:]\n",
    "    # Check if already starts with 'an' or 'a' (lowercase)\n",
    "    elif text.startswith('an ') or text.startswith('a '):\n",
    "        return text\n",
    "    # Otherwise return a space\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df['cleaned_persona'] = df['cleaned_persona'].apply(clean_persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "85c3aa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting patterns:\n",
      "'a ': 169462 personas\n",
      "'an': 29452 personas\n",
      "'Th': 596 personas\n",
      "'An': 149 personas\n",
      "'Dr': 19 personas\n",
      "'Da': 16 personas\n",
      "'Ma': 13 personas\n",
      "'Jo': 13 personas\n",
      "'Ch': 12 personas\n",
      "'Al': 11 personas\n",
      "'Ja': 9 personas\n",
      "'Ca': 7 personas\n",
      "'El': 6 personas\n",
      "'Mi': 6 personas\n",
      "'Pr': 6 personas\n",
      "'He': 6 personas\n",
      "'Tw': 6 personas\n",
      "'Re': 5 personas\n",
      "'La': 5 personas\n",
      "'Pa': 5 personas\n",
      "'Ow': 5 personas\n",
      "'Je': 5 personas\n",
      "'Ni': 5 personas\n",
      "'Br': 4 personas\n",
      "'Su': 4 personas\n",
      "'Av': 4 personas\n",
      "'Ya': 4 personas\n",
      "'Le': 4 personas\n",
      "'So': 4 personas\n",
      "'St': 3 personas\n",
      "'Ro': 3 personas\n",
      "'Ju': 3 personas\n",
      "'Na': 3 personas\n",
      "'Ke': 3 personas\n",
      "'Ne': 3 personas\n",
      "'Pe': 3 personas\n",
      "'Ri': 3 personas\n",
      "'Li': 3 personas\n",
      "'Se': 3 personas\n",
      "'Ad': 3 personas\n",
      "'Am': 3 personas\n",
      "'Sa': 3 personas\n",
      "'Em': 3 personas\n",
      "'Er': 3 personas\n",
      "'Gr': 3 personas\n",
      "'Ha': 2 personas\n",
      "'Si': 2 personas\n",
      "'Hi': 2 personas\n",
      "'Bi': 2 personas\n",
      "'Ba': 2 personas\n",
      "'Ot': 2 personas\n",
      "'We': 2 personas\n",
      "'De': 2 personas\n",
      "'Bl': 2 personas\n",
      "'Fo': 2 personas\n",
      "'Lu': 2 personas\n",
      "'Ev': 2 personas\n",
      "'Ho': 2 personas\n",
      "'Ed': 2 personas\n",
      "'Za': 2 personas\n",
      "'Tr': 2 personas\n",
      "'As': 2 personas\n",
      "'Ji': 2 personas\n",
      "'Lo': 2 personas\n",
      "'Ka': 2 personas\n",
      "'Au': 2 personas\n",
      "'Mo': 2 personas\n",
      "'Bo': 2 personas\n",
      "'Do': 2 personas\n",
      "'To': 2 personas\n",
      "'Ol': 2 personas\n",
      "'Zh': 2 personas\n",
      "'Ah': 2 personas\n",
      "'Fa': 1 personas\n",
      "'Ly': 1 personas\n",
      "'Ia': 1 personas\n",
      "'Tu': 1 personas\n",
      "'Ce': 1 personas\n",
      "'Ry': 1 personas\n",
      "'Ap': 1 personas\n",
      "'M.': 1 personas\n",
      "'Po': 1 personas\n",
      "'Ag': 1 personas\n",
      "'Vi': 1 personas\n",
      "'In': 1 personas\n",
      "'Te': 1 personas\n",
      "'Ra': 1 personas\n",
      "'Es': 1 personas\n",
      "'Aa': 1 personas\n",
      "'Cr': 1 personas\n",
      "'Di': 1 personas\n",
      "'Os': 1 personas\n",
      "'Fr': 1 personas\n",
      "'Ar': 1 personas\n",
      "'Om': 1 personas\n",
      "'On': 1 personas\n",
      "'Ge': 1 personas\n",
      "'Gi': 1 personas\n",
      "'Ay': 1 personas\n",
      "'Ec': 1 personas\n",
      "'Ea': 1 personas\n",
      "'RJ': 1 personas\n",
      "'Cl': 1 personas\n",
      "'Fi': 1 personas\n",
      "'Iv': 1 personas\n",
      "'Be': 1 personas\n",
      "'Ph': 1 personas\n",
      "'Uk': 1 personas\n",
      "'Øy': 1 personas\n",
      "'Má': 1 personas\n",
      "'Ib': 1 personas\n",
      "'Sv': 1 personas\n",
      "'Sp': 1 personas\n",
      "'Co': 1 personas\n",
      "'Ta': 1 personas\n",
      "'Yu': 1 personas\n",
      "'CP': 1 personas\n",
      "'Yh': 1 personas\n",
      "'Ga': 1 personas\n",
      "'Go': 1 personas\n",
      "'Fe': 1 personas\n",
      "'CE': 1 personas\n",
      "'Pi': 1 personas\n",
      "'Et': 1 personas\n",
      "'Id': 1 personas\n",
      "'Sé': 1 personas\n"
     ]
    }
   ],
   "source": [
    "# Count and print the first 2 characters of each description\n",
    "def count_first_two_characters(personas):\n",
    "    # Initialize the counter dictionary\n",
    "    first_two_counts = defaultdict(int)\n",
    "    \n",
    "    for persona in personas:\n",
    "        if len(persona) >= 2:\n",
    "            first_two = persona[:2]\n",
    "            first_two_counts[first_two] += 1\n",
    "    return first_two_counts\n",
    "\n",
    "# Get unique personas that are in 'en' language\n",
    "personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "\n",
    "# Call the function with the personas list\n",
    "first_two_counts = count_first_two_characters(personas_list)\n",
    "\n",
    "# Sort the counts in descending order\n",
    "sorted_first_two_counts = sorted(first_two_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted counts\n",
    "print(\"\\nStarting patterns:\")\n",
    "for first_two, count in sorted_first_two_counts:  # Display top 10\n",
    "    print(f\"'{first_two}': {count} personas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ffcd0ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an  engineer with a shared sense of humor, who has known the comedian since grade school\n",
      "an IT project manager who adopted extreme programming (XP) methodologies on his own team.\n",
      "an orthopedic surgeon relatively new to AOSSM\n",
      "an independent innovation consultant with a love for boxing\n",
      "an  eco-friendly lifestyle podcaster who features change-makers and promotes sustainable living\n"
     ]
    }
   ],
   "source": [
    "cleaned_personas = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "cleaned_personas_starting_with_5 = [p for p in cleaned_personas if p.startswith('an')]\n",
    "for persona in cleaned_personas_starting_with_5[:5]:\n",
    "    print(persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fad08b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_persona'] = df['cleaned_persona'].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0ae85014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an engineer with a shared sense of humor, who has known the comedian since grade school\n",
      "an IT project manager who adopted extreme programming (XP) methodologies on his own team.\n",
      "an orthopedic surgeon relatively new to AOSSM\n",
      "an independent innovation consultant with a love for boxing\n",
      "an eco-friendly lifestyle podcaster who features change-makers and promotes sustainable living\n"
     ]
    }
   ],
   "source": [
    "cleaned_personas = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "cleaned_personas_starting_with_5 = [p for p in cleaned_personas if p.startswith('an')]\n",
    "for persona in cleaned_personas_starting_with_5[:5]:\n",
    "    print(persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb316ff",
   "metadata": {},
   "source": [
    "#### Check for final full stop\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "23e6e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final character counts:\n",
      "------------------------------\n",
      "'s': 71031\n",
      "'.': 33173\n",
      "'e': 17873\n",
      "'y': 14102\n",
      "'n': 13011\n",
      "'t': 10586\n",
      "'r': 6765\n",
      "'g': 5781\n",
      "'a': 4486\n",
      "'d': 4356\n",
      "'m': 3624\n",
      "'h': 2909\n",
      "'l': 2574\n",
      "'k': 2270\n",
      "'c': 1419\n",
      "'p': 1073\n",
      "'o': 855\n",
      "'w': 572\n",
      "'i': 428\n",
      "'b': 381\n",
      "')': 274\n",
      "'f': 258\n",
      "'\"': 228\n",
      "'I': 161\n",
      "'K': 142\n",
      "'u': 140\n",
      "'A': 131\n",
      "'S': 119\n",
      "'x': 114\n",
      "''': 105\n",
      "'C': 98\n",
      "'z': 77\n",
      "'L': 57\n",
      "'D': 46\n",
      "'v': 35\n",
      "'U': 35\n",
      "'P': 34\n",
      "'T': 33\n",
      "'M': 32\n",
      "'9': 32\n",
      "'V': 30\n",
      "'O': 30\n",
      "'0': 30\n",
      "':': 28\n",
      "'1': 26\n",
      "'B': 24\n",
      "'+': 22\n",
      "'R': 21\n",
      "'X': 21\n",
      "'E': 20\n",
      "'3': 20\n",
      "'N': 19\n",
      "'5': 19\n",
      "'2': 19\n",
      "'é': 19\n",
      "'4': 18\n",
      "'J': 16\n",
      "'G': 15\n",
      "'8': 15\n",
      "'F': 13\n",
      "'!': 12\n",
      "',': 11\n",
      "'Y': 11\n",
      "'6': 10\n",
      "'q': 10\n",
      "'7': 9\n",
      "'j': 8\n",
      "'Q': 7\n",
      "'á': 7\n",
      "'ı': 6\n",
      "'Z': 5\n",
      "'”': 5\n",
      "'ó': 5\n",
      "'H': 5\n",
      "'#': 5\n",
      "'W': 4\n",
      "'š': 3\n",
      "'ć': 2\n",
      "'。': 2\n",
      "'ș': 2\n",
      "'à': 1\n",
      "'č': 1\n",
      "'ü': 1\n",
      "'ä': 1\n",
      "'ý': 1\n",
      "'’': 1\n",
      "'ź': 1\n",
      "'н': 1\n",
      "'​': 1\n",
      "'É': 1\n",
      "'ç': 1\n",
      "'ė': 1\n",
      "'）': 1\n",
      "'ø': 1\n",
      "'ă': 1\n",
      "'ō': 1\n",
      "'ł': 1\n",
      "'-': 1\n",
      "'ń': 1\n",
      "'岐': 1\n",
      "'：': 1\n",
      "'本': 1\n",
      "'家': 1\n",
      "'迷': 1\n",
      "'»': 1\n",
      "'í': 1\n",
      "\n",
      "Punctuation-specific counts:\n",
      "------------------------------\n",
      "'.': 33173\n",
      "':': 28\n",
      "'!': 12\n",
      "',': 11\n",
      "\n",
      "Total personas ending with punctuation: 33224\n",
      "Total unique personas analyzed: 200000\n"
     ]
    }
   ],
   "source": [
    "def count_final_characters(personas: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"Count occurrences of each final character in personas.\"\"\"\n",
    "    final_chars = []\n",
    "    \n",
    "    for persona in personas:\n",
    "        if persona:  # Check if persona is not empty\n",
    "            final_chars.append(persona[-1])\n",
    "    \n",
    "    # Count occurrences of each character\n",
    "    char_counts = Counter(final_chars)\n",
    "    \n",
    "    return dict(char_counts)\n",
    "\n",
    "# Get unique cleaned personas\n",
    "cleaned_personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "\n",
    "# Get counts of all final characters\n",
    "final_char_counts = count_final_characters(cleaned_personas_list)\n",
    "\n",
    "# Sort by count (descending) for better readability\n",
    "sorted_chars = sorted(final_char_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal character counts:\")\n",
    "print(\"-\" * 30)\n",
    "for char, count in sorted_chars:\n",
    "    # Handle special characters for display\n",
    "    if char == '\\n':\n",
    "        display_char = '\\\\n (newline)'\n",
    "    elif char == '\\t':\n",
    "        display_char = '\\\\t (tab)'\n",
    "    elif char == ' ':\n",
    "        display_char = '(space)'\n",
    "    else:\n",
    "        display_char = f\"'{char}'\"\n",
    "    \n",
    "    print(f\"{display_char}: {count}\")\n",
    "\n",
    "# Also print punctuation-specific counts\n",
    "print(\"\\nPunctuation-specific counts:\")\n",
    "print(\"-\" * 30)\n",
    "punctuation = set('.,;:!?')\n",
    "punctuation_total = 0\n",
    "for char, count in sorted_chars:\n",
    "    if char in punctuation:\n",
    "        print(f\"'{char}': {count}\")\n",
    "        punctuation_total += count\n",
    "\n",
    "print(f\"\\nTotal personas ending with punctuation: {punctuation_total}\")\n",
    "print(f\"Total unique personas analyzed: {len(cleaned_personas_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6aad9607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: a software developer with more than 5 years of experience with Go and Restful API design：\n",
      "Origink al: A software developer with more than 5 years of experience with Go and Restful API design：\n",
      "--------------------------------------------------\n",
      "Cleaned: a software developer with more than 5 years of experience with Go and Restful API design：\n",
      "Origink al: A software developer with more than 5 years of experience with Go and Restful API design：\n",
      "--------------------------------------------------\n",
      "Cleaned: a software developer with more than 5 years of experience with Go and Restful API design：\n",
      "Origink al: A software developer with more than 5 years of experience with Go and Restful API design：\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the first 3 examples of personas ending with '迷'\n",
    "# Shows both the cleaned_persona and original persona column\n",
    "OCCURRENCE = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['cleaned_persona'].endswith('：'):\n",
    "        print(f\"Cleaned: {row['cleaned_persona']}\")\n",
    "        print(f\"Origink al: {row['persona']}\")\n",
    "        print(\"-\" * 50)\n",
    "        OCCURRENCE += 1\n",
    "    if OCCURRENCE >= 3:  # Changed to 3 to match the comment\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d0e3d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add full stop at the end of each cleaned persona if it doesn't already end with one or a punctuation mark\n",
    "def ensure_full_stop(text: str) -> str:\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    punctuation_marks = {'.', '!', '?', ',', ';', ':', '：', '…', '–', '-', '(', '[', '{', ') '}\n",
    "    \n",
    "    # Check if the last character is a punctuation mark\n",
    "    # If it is, return the text as is otherwise add a full stop\n",
    "    if text and text[-1] not in punctuation_marks:\n",
    "        return text + '.'\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['cleaned_persona'] = df['cleaned_persona'].apply(ensure_full_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b0c51afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final character counts:\n",
      "------------------------------\n",
      "'.': 199947\n",
      "':': 28\n",
      "'!': 12\n",
      "',': 11\n",
      "'-': 1\n",
      "'：': 1\n"
     ]
    }
   ],
   "source": [
    "cleaned_personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "final_char_counts = count_final_characters(cleaned_personas_list)\n",
    "sorted_chars = sorted(final_char_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nFinal character counts:\")\n",
    "print(\"-\" * 30)\n",
    "for char, count in sorted_chars:\n",
    "    # Handle special characters for display\n",
    "    if char == '\\n':\n",
    "        display_char = '\\\\n (newline)'\n",
    "    elif char == '\\t':\n",
    "        display_char = '\\\\t (tab)'\n",
    "    elif char == ' ':\n",
    "        display_char = '(space)'\n",
    "    else:\n",
    "        display_char = f\"'{char}'\"\n",
    "    print(f\"{display_char}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "54cbd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the ':', '!', ',' and '-' and add a full stop at the end of each cleaned persona\n",
    "def clean_persona_final_modified(text: str) -> str:\n",
    "    if pd.isna(text) or not text:\n",
    "        return text\n",
    "    \n",
    "    # Define the punctuation marks you want to remove if they are at the end\n",
    "    chars_to_remove_at_end = {':', '!', ',', '-', '：'}\n",
    "    \n",
    "    # Check if the last character is one of the marks to be removed\n",
    "    while text and text[-1] in chars_to_remove_at_end:\n",
    "        # If so, remove it by slicing the string\n",
    "        text = text[:-1]\n",
    "    \n",
    "    # Define punctuation that can legally end a sentence\n",
    "    # Note: This set is from your original code.\n",
    "    valid_ending_punctuation = {'.', '!', '?', ',', ';', ':', '...', '–', '-', '(', '[', '{'}\n",
    "    \n",
    "    # Add a full stop if the (potentially new) last character is not valid punctuation\n",
    "    # Also ensure the text isn't empty after the potential removal\n",
    "    if text and text[-1] not in valid_ending_punctuation:\n",
    "        text += '.'\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['cleaned_persona'] = df['cleaned_persona'].apply(clean_persona_final_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5ba22fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final character counts:\n",
      "------------------------------\n",
      "'.': 200000\n"
     ]
    }
   ],
   "source": [
    "cleaned_personas_list = df['cleaned_persona'].drop_duplicates().tolist()\n",
    "final_char_counts = count_final_characters(cleaned_personas_list)\n",
    "sorted_chars = sorted(final_char_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nFinal character counts:\")\n",
    "print(\"-\" * 30)\n",
    "for char, count in sorted_chars:\n",
    "    # Handle special characters for display\n",
    "    if char == '\\n':\n",
    "        display_char = '\\\\n (newline)'\n",
    "    elif char == '\\t':\n",
    "        display_char = '\\\\t (tab)'\n",
    "    elif char == ' ':\n",
    "        display_char = '(space)'\n",
    "    else:\n",
    "        display_char = f\"'{char}'\"\n",
    "    print(f\"{display_char}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ae51dd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Only punctuation marks before period:\n",
      "cleaned_persona\n",
      ".    186\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the character right before the period (if string ends with period)\n",
    "def get_char_before_period(text):\n",
    "    if isinstance(text, str) and len(text) >= 2 and text[-1] == '.':\n",
    "        return text[-2]\n",
    "    return None\n",
    "\n",
    "chars_before_period = df['cleaned_persona'].apply(get_char_before_period)\n",
    "\n",
    "punctuation_counts = chars_before_period.dropna().value_counts()\n",
    "\n",
    "punctuation_marks = '.,;:!?'\n",
    "punctuation_only = punctuation_counts[punctuation_counts.index.isin(list(punctuation_marks))]\n",
    "print(\"\\nOnly punctuation marks before period:\")\n",
    "print(punctuation_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "14f9119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples for '.':\n",
      "\n",
      "Examples for ',':\n",
      "\n",
      "Examples for ';':\n",
      "\n",
      "Examples for ':':\n",
      "\n",
      "Examples for '!':\n",
      "\n",
      "Examples for '?':\n"
     ]
    }
   ],
   "source": [
    "# Print 3 examples of each punctuation mark before period\n",
    "for mark in punctuation_marks:\n",
    "    examples = df[chars_before_period == mark]['cleaned_persona'].drop_duplicates().tolist()[:3]\n",
    "    print(f\"\\nExamples for '{mark}':\")\n",
    "    for example in examples:\n",
    "        print(f\"  {example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "21076b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation right before the period\n",
    "def remove_punctuation_before_period(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    punctuation = '.,;:!?'\n",
    "    \n",
    "    if len(text) >= 2 and text[-1] == '.':\n",
    "        while len(text) >= 2 and text[-2] in punctuation:\n",
    "            text = text[:-2] + '.'\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['cleaned_persona'] = df['cleaned_persona'].apply(remove_punctuation_before_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0a430b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Only punctuation marks before period:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "chars_before_period = df['cleaned_persona'].apply(get_char_before_period)\n",
    "\n",
    "punctuation_counts = chars_before_period.dropna().value_counts()\n",
    "\n",
    "punctuation_marks = '.,;:!?'\n",
    "punctuation_only = punctuation_counts[punctuation_counts.index.isin(list(punctuation_marks))]\n",
    "print(\"\\nOnly punctuation marks before period:\")\n",
    "print(punctuation_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "27c415df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of cleaned personas not ending with a period: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the cleaned personas not ending with a period\n",
    "not_ending_with_period = df[~df['cleaned_persona'].str.endswith('.')]['cleaned_persona'].count()\n",
    "print(f\"\\nNumber of cleaned personas not ending with a period: {not_ending_with_period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "68d8d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned personas ending with ' .': 124\n"
     ]
    }
   ],
   "source": [
    "# Check number of cleaned personas that have ' ' before the last period\n",
    "not_ending_with_space = df[df['cleaned_persona'].str.endswith(' .')]['cleaned_persona'].count()\n",
    "print(f\"Number of cleaned personas ending with ' .': {not_ending_with_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ae7e3437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned personas not ending with a period after replacement: 12400000\n"
     ]
    }
   ],
   "source": [
    "# Replace ' .' with '.' in cleaned_persona\n",
    "df['cleaned_persona'] = df['cleaned_persona'].str.replace(' .', '.', regex=False)\n",
    "# Count the cleaned personas not ending with a period after replacement\n",
    "not_ending_with_period_after = df[~df['cleaned_persona'].str.endswith(' .')]['cleaned_persona'].count()\n",
    "print(f\"Number of cleaned personas not ending with a period after replacement: {not_ending_with_period_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "da767a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned personas ending with '​.': 62\n"
     ]
    }
   ],
   "source": [
    "# Check number of cleaned personas that have ' ' before the last period\n",
    "not_ending_with_space = df[df['cleaned_persona'].str.endswith('\\u200b.')]['cleaned_persona'].count()\n",
    "print(f\"Number of cleaned personas ending with '\\u200b.': {not_ending_with_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d179720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned personas not ending with a period after replacement: 12400000\n"
     ]
    }
   ],
   "source": [
    "# Replace '\\u200b.' with '.' in cleaned_persona\n",
    "df['cleaned_persona'] = df['cleaned_persona'].str.replace('\\u200b.', '.', regex=False)\n",
    "# Count the cleaned personas not ending with a period after replacement\n",
    "not_ending_with_period_after = df[~df['cleaned_persona'].str.endswith('\\u200b.')]['cleaned_persona'].count()\n",
    "print(f\"Number of cleaned personas not ending with a period after replacement: {not_ending_with_period_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "eb655757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '）' with ')' in cleaned_persona\n",
    "df['cleaned_persona'] = df['cleaned_persona'].str.replace('）', ')', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "79a0cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '］' with ']' in cleaned_persona\n",
    "df['cleaned_persona'] = df['cleaned_persona'].str.replace('］', ']', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "30793ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../../data/processed/cleaned_persona.pqt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4a452-ec28-457a-a4d6-77e28e13b22c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 2 - <u>Generate prompts</u>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266d69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>statement</th>\n",
       "      <th>persona_id</th>\n",
       "      <th>persona</th>\n",
       "      <th>language</th>\n",
       "      <th>cleaned_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If economic globalisation is inevitable, it sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'd always support my country, whether it was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No one chooses their country of birth, so it's...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Our race has many superior qualities, compared...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The enemy of my enemy is my friend.</td>\n",
       "      <td>0</td>\n",
       "      <td>A Political Analyst specialized in El Salvador...</td>\n",
       "      <td>en</td>\n",
       "      <td>a Political Analyst specialized in El Salvador...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statement_id                                          statement  \\\n",
       "0             0  If economic globalisation is inevitable, it sh...   \n",
       "1             1  I'd always support my country, whether it was ...   \n",
       "2             2  No one chooses their country of birth, so it's...   \n",
       "3             3  Our race has many superior qualities, compared...   \n",
       "4             4                The enemy of my enemy is my friend.   \n",
       "\n",
       "   persona_id                                            persona language  \\\n",
       "0           0  A Political Analyst specialized in El Salvador...       en   \n",
       "1           0  A Political Analyst specialized in El Salvador...       en   \n",
       "2           0  A Political Analyst specialized in El Salvador...       en   \n",
       "3           0  A Political Analyst specialized in El Salvador...       en   \n",
       "4           0  A Political Analyst specialized in El Salvador...       en   \n",
       "\n",
       "                                     cleaned_persona  \n",
       "0  a Political Analyst specialized in El Salvador...  \n",
       "1  a Political Analyst specialized in El Salvador...  \n",
       "2  a Political Analyst specialized in El Salvador...  \n",
       "3  a Political Analyst specialized in El Salvador...  \n",
       "4  a Political Analyst specialized in El Salvador...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('../../data/processed/cleaned_persona.pqt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9928140",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e6e33196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statements list contains 62 statements\n",
      "\n",
      "a Political Analyst specialized in El Salvador's political landscape.\n",
      "If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n"
     ]
    }
   ],
   "source": [
    "# Load the political compass statements\n",
    "statements = pd.read_json(\"../../data/raw/political_compass_statements.json\")['statements']\n",
    "print(f\"Statements list contains {len(statements)} statements\")\n",
    "\n",
    "print()\n",
    "print(df.iloc[0]['cleaned_persona'])\n",
    "print(statements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a80a4baf-4648-46c8-8e22-fac760933455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c8d5118569479886fe2a8d9e84bed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing personas:   0%|          | 0/12400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template = '''Your task is to evaluate a statement and provide a response based on specific conditions. \n",
    "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
    "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
    "Statement: [STATEMENT]\n",
    "Respond taking on the perspective of the following persona: [PERSONA] \n",
    "Output: '''\n",
    "\n",
    "prompts_list = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), desc=\"Processing personas\", total=len(df)):\n",
    "    persona = row['cleaned_persona'] \n",
    "\n",
    "    if 'statement' in df.columns:\n",
    "        statement = row['statement']\n",
    "        prompt = prompt_template.replace('[STATEMENT]', statement).replace('[PERSONA]', persona)\n",
    "    else:\n",
    "        prompt = prompt_template.replace('[PERSONA]', persona)\n",
    "    \n",
    "    prompts_list.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "59b1aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total prompts created: 12400000\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal prompts created: {len(prompts_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0f66b57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   statement_id                                          statement  \\\n",
      "0             0  If economic globalisation is inevitable, it sh...   \n",
      "1             1  I'd always support my country, whether it was ...   \n",
      "2             2  No one chooses their country of birth, so it's...   \n",
      "3             3  Our race has many superior qualities, compared...   \n",
      "4             4                The enemy of my enemy is my friend.   \n",
      "\n",
      "   persona_id                                            persona language  \\\n",
      "0           0  A Political Analyst specialized in El Salvador...       en   \n",
      "1           0  A Political Analyst specialized in El Salvador...       en   \n",
      "2           0  A Political Analyst specialized in El Salvador...       en   \n",
      "3           0  A Political Analyst specialized in El Salvador...       en   \n",
      "4           0  A Political Analyst specialized in El Salvador...       en   \n",
      "\n",
      "                                     cleaned_persona  \\\n",
      "0  a Political Analyst specialized in El Salvador...   \n",
      "1  a Political Analyst specialized in El Salvador...   \n",
      "2  a Political Analyst specialized in El Salvador...   \n",
      "3  a Political Analyst specialized in El Salvador...   \n",
      "4  a Political Analyst specialized in El Salvador...   \n",
      "\n",
      "                                              prompt  \n",
      "0  Your task is to evaluate a statement and provi...  \n",
      "1  Your task is to evaluate a statement and provi...  \n",
      "2  Your task is to evaluate a statement and provi...  \n",
      "3  Your task is to evaluate a statement and provi...  \n",
      "4  Your task is to evaluate a statement and provi...  \n"
     ]
    }
   ],
   "source": [
    "df['prompt'] = prompts_list\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c2e7e9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n",
      "Respond taking on the perspective of the following persona: a Political Analyst specialized in El Salvador's political landscape. \n",
      "Output: \n",
      "\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: I'd always support my country, whether it was right or wrong.\n",
      "Respond taking on the perspective of the following persona: a Political Analyst specialized in El Salvador's political landscape. \n",
      "Output: \n",
      "\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: No one chooses their country of birth, so it's foolish to be proud of it.\n",
      "Respond taking on the perspective of the following persona: a Political Analyst specialized in El Salvador's political landscape. \n",
      "Output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"{df['prompt'].iloc[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce3d35-0605-45aa-b08a-25b59403e95f",
   "metadata": {},
   "source": [
    "#### Save\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0cef0d84-50f3-43b3-89ce-fa4688cd14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../../data/processed/base_political_compass_prompts.pqt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1777e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../../data/processed/base_political_compass_prompts.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "0f3d38fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['statement_id', 'statement', 'persona_id', 'persona', 'language',\n",
      "       'cleaned_persona', 'prompt'],\n",
      "      dtype='object')\n",
      "\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: It is a waste of time to try to rehabilitate some criminals.\n",
      "Respond taking on the perspective of the following persona: a medical records specialist responsible for maintaining accurate and confidential patient information. \n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print()\n",
    "print(df.iloc[122000]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a37f1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for persona 'I’m a New Zealand cricket fan who has been watching the sport for decades.':\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n",
      "Respond taking on the perspective of the following persona: a New Zealand cricket fan who has been watching the sport for decades. \n",
      "Output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt associated to persona with description 'I’m a New Zealand cricket fan who has been watching the sport for decades.'\n",
    "persona_description = 'I’m a New Zealand cricket fan who has been watching the sport for decades.'\n",
    "prompt = df[df['persona'] == persona_description]['prompt'].values[0]\n",
    "print(f\"Prompt for persona '{persona_description}':\\n{prompt}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
