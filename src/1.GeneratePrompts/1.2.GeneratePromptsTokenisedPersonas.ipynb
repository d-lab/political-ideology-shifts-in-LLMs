{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86bfd10f",
   "metadata": {},
   "source": [
    "# Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab841083-6167-40ff-b5bc-434373b9c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default sys.path: ['/Users/uqpberna/miniconda3/envs/personas/lib/python312.zip', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/lib-dynload', '', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/site-packages', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/site-packages/setuptools/_vendor']\n",
      "Project root: /Users/uqpberna/Documents/Code/Mapping_and_Influencing_LLMs_Political_Leaning/extension/src\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reload all modules every time before executing the Python code\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f'default sys.path: {sys.path}')\n",
    "# Probably not needed for pycharm but needed for vscode -----------------------------------\n",
    "PROJ_ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "sys.path.append(PROJ_ROOT)\n",
    "print(f'Project root: {PROJ_ROOT}')\n",
    "# Probably not needed for pycharm but needed for vscode -----------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc597a-a395-450e-8862-642435d608aa",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1 - <u>Tokenize persona</u>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538f2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data/processed/cleaned_persona.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ad385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12400000, 6)\n",
      "Index(['statement_id', 'statement', 'persona_id', 'persona', 'language',\n",
      "       'cleaned_persona'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8065d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of personas not starting with 'an' or 'a ' (first 20 examples):\n",
      "- Fabian, a lawyer from Bowmans who was recommended.\n",
      "- Hatim El Otmani himself.\n",
      "- Brian, a retired firefighter who assists Mehmet in organizing disaster preparedness workshops for the community.\n",
      "- Markus Wallner's number one fan who religiously follows his career.\n",
      "- The Chief Risk Officer of a financial corporation, responsible for setting the risk management strategy and relying on the analyst's insights to make informed decisions.\n",
      "- Margarethe Jodl, a time traveler who has arrived in the present and discovered the current state of the women's rights movement.\n",
      "- The owner of a popular BBQ joint who caters delicious southern-style food for festival attendees.\n",
      "- Rey, an iconic character from the Star Wars universe, who feels excited to see fans celebrate their beloved saga.\n",
      "- The owner of a small bakery who provides healthy snacks for extracurricular activities.\n",
      "- The owner of a rival comic book shop who prides themselves on a rare and classic collection.\n",
      "- Elijah, head of an IT department in a governmental organization, wrestling with complexities involved in the conduct of elections.\n",
      "- The wife of Steve Whitmire, devoted and proud of her husband's achievements.\n",
      "- Sipho, a 25-year-old South African political science graduate student who hopes to run for local office someday.\n",
      "- Lydia Tederick, a professional reflecting on her career and passion for preserving history.\n",
      "- The president of the Model United Nations Club, who orchestrates simulations of UN sessions.\n",
      "- The founder of a popular organic coffee chain in the United States.\n",
      "- Dr. Maria Silva, a renowned expert in the research area, who provides guidance and valuable insights to the student.\n",
      "- The owner of the team that the retired football player played for, who admires their loyalty and offers them a role in the organization.\n",
      "- The reigning sprint champion at a neighboring high school aiming to defend his title.\n",
      "- The head of a local Buddhist center, responsible for organizing events and supporting the monk's teachings.\n"
     ]
    }
   ],
   "source": [
    "# Print examples of personas not starting with 'an' or 'a '\n",
    "def print_examples_not_starting_with_an_a(df, n=5):\n",
    "    examples = df[~df['cleaned_persona'].str.startswith(('an ', 'a '))]['cleaned_persona'].drop_duplicates().head(n)\n",
    "    print(f\"\\nExamples of personas not starting with 'an' or 'a ' (first {n} examples):\")\n",
    "    for persona in examples:\n",
    "        print(f\"- {persona}\")\n",
    "\n",
    "print_examples_not_starting_with_an_a(df, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_persona'] = df['cleaned_persona'].apply(\n",
    "    lambda x: '[TOKEN] ' + x[2:] if x.startswith('a ') else \\\n",
    "              '[TOKEN] ' + x[3:] if x.startswith('an ') else \\\n",
    "              '[TOKEN] ' + x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../../data/processed/cleaned_persona_tokenized.pqt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320feef",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 2 - <u>Generate prompts</u>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7361bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data/processed/cleaned_persona_tokenized.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f323c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['statement_id', 'statement', 'persona_id', 'persona', 'language',\n",
      "       'cleaned_persona', 'tokenized_persona'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849f6daf-fbb8-4ac0-80c5-73cad8ef6bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKEN] professional fitness trainer who upholds two fascinating doctrines: \"Community Involvement\" and \"Commitment to Charity,\" deeply appreciating activities that foster fitness while providing opportunities to give back to society.\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "persona = pd.read_parquet('../../data/processed/cleaned_persona_tokenized.pqt')['tokenized_persona'].drop_duplicates().tolist()\n",
    "print(persona[120])\n",
    "print(len(persona))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b0c5a2-d557-4a21-9deb-098fa2173719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statements list contains 62 statements\n"
     ]
    }
   ],
   "source": [
    "statements = pd.read_json(\"../../data/raw/political_compass_statements.json\")['statements'] # list containing the 62 political stetements\n",
    "print(f\"Statements list contains {len(statements)} statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90dce142",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''Your task is to evaluate a statement and provide a response based on specific conditions. \n",
    "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
    "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
    "Statement: [STATEMENT]\n",
    "Respond taking on the perspective of the following persona: [PERSONA] \n",
    "Output: '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787f056",
   "metadata": {},
   "source": [
    "#### Right Authoritarian injection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee62b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_list = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), desc=\"Processing personas\", total=len(df)):\n",
    "    persona = row['tokenized_persona'] \n",
    "\n",
    "    if 'statement' in df.columns:\n",
    "        statement = row['statement']\n",
    "        prompt = prompt_template.replace('[STATEMENT]', statement).replace('[PERSONA]', persona).replace('[TOKEN]', 'a right leaning authoritarian')\n",
    "    else:\n",
    "        prompt = prompt_template.replace('[PERSONA]', persona)\n",
    "    \n",
    "    prompts_list.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7204697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = prompts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff39db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All persona prompts are compliant.\n",
      "\n",
      "Original DataFrame shape: (12400000, 8)\n"
     ]
    }
   ],
   "source": [
    "non_compliant_prompts = []\n",
    "persona_instruction = 'Respond taking on the perspective of the following persona: '\n",
    "expected_start = 'a right leaning authoritarian '\n",
    "\n",
    "for prompt in df['prompt']:\n",
    "    # Check if this is a persona prompt\n",
    "    if persona_instruction in prompt:\n",
    "        # Check if the text after the instruction has the correct start\n",
    "        if not prompt.split(persona_instruction, 1)[1].startswith(expected_start):\n",
    "            non_compliant_prompts.append(prompt)\n",
    "\n",
    "# Report the findings\n",
    "if non_compliant_prompts:\n",
    "    print(f\"Found {len(non_compliant_prompts)} non-compliant prompts:\")\n",
    "    for p in non_compliant_prompts:\n",
    "        print(f\" - {p}\")\n",
    "else:\n",
    "    print(\"✅ All persona prompts are compliant.\")\n",
    "\n",
    "print(f\"\\nOriginal DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401ef97b-8f3c-418b-b8e1-1074bf34202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12400000, 5)\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n",
      "Respond taking on the perspective of the following persona: a right leaning authoritarian Political Analyst specialized in El Salvador's political landscape.\n",
      "Output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.iloc[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a9293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../../data/processed/right_authoritarian_political_compass_prompts.pqt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "727f4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../../data/processed/right_authoritarian_political_compass_prompts.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2e2309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: The freer the market, the freer the people.\n",
      "Respond taking on the perspective of the following persona: a right leaning authoritarian biology teacher who sees no practical importance in studying astronomy in a science curriculum.\n",
      "Output: \n",
      "\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: Abortion, when the woman's life is not threatened, should always be illegal.\n",
      "Respond taking on the perspective of the following persona: a right leaning authoritarian biology teacher who sees no practical importance in studying astronomy in a science curriculum.\n",
      "Output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1234564]['prompt'])\n",
    "print(df.iloc[1234345]['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234018b",
   "metadata": {},
   "source": [
    "#### Left Libertarian injection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1886c430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c35e0a6b8a7459d812488c09f9ed0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing personas:   0%|          | 0/12400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_list = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), desc=\"Processing personas\", total=len(df)):\n",
    "    persona = row['tokenized_persona'] \n",
    "\n",
    "    if 'statement' in df.columns:\n",
    "        statement = row['statement']\n",
    "        prompt = prompt_template.replace('[STATEMENT]', statement).replace('[PERSONA]', persona).replace('[TOKEN]', 'a left leaning libertarian')\n",
    "    else:\n",
    "        prompt = prompt_template.replace('[PERSONA]', persona)\n",
    "    \n",
    "    prompts_list.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f430e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = prompts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7a11feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All persona prompts are compliant.\n",
      "\n",
      "Original DataFrame shape: (12400000, 8)\n"
     ]
    }
   ],
   "source": [
    "non_compliant_prompts = []\n",
    "persona_instruction = 'Respond taking on the perspective of the following persona: '\n",
    "expected_start = 'a left leaning libertarian '\n",
    "\n",
    "for prompt in df['prompt']:\n",
    "    # Check if this is a persona prompt\n",
    "    if persona_instruction in prompt:\n",
    "        # Check if the text after the instruction has the correct start\n",
    "        if not prompt.split(persona_instruction, 1)[1].startswith(expected_start):\n",
    "            non_compliant_prompts.append(prompt)\n",
    "\n",
    "# Report the findings\n",
    "if non_compliant_prompts:\n",
    "    print(f\"Found {len(non_compliant_prompts)} non-compliant prompts:\")\n",
    "    for p in non_compliant_prompts:\n",
    "        print(f\" - {p}\")\n",
    "else:\n",
    "    print(\"✅ All persona prompts are compliant.\")\n",
    "\n",
    "print(f\"\\nOriginal DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16aea944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12400000, 8)\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n",
      "Respond taking on the perspective of the following persona: a left leaning libertarian Political Analyst specialized in El Salvador's political landscape. \n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.iloc[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc8ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../../data/processed/left_libertarian_political_compass_prompts.pqt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e40c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../../data/processed/left_libertarian_political_compass_prompts.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a302b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: The freer the market, the freer the people.\n",
      "Respond taking on the perspective of the following persona: a left leaning libertarian biology teacher who sees no practical importance in studying astronomy in a science curriculum.\n",
      "Output: \n",
      "\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: Abortion, when the woman's life is not threatened, should always be illegal.\n",
      "Respond taking on the perspective of the following persona: a left leaning libertarian biology teacher who sees no practical importance in studying astronomy in a science curriculum.\n",
      "Output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1234564]['prompt'])\n",
    "print(df.iloc[1234345]['prompt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
